---
title: "Trump's Tweetanalyse"
author: "Thomas de Beus"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    css: style.css
    toc: TRUE
    toc_depth: 5
    theme: journal
    code_folding: hide
    number_sections: true
---
<style>
  #TOC {
    position: fixed;
    left: 0;
    top: 10;
    width: 300px;
    height: 100%;
    overflow:auto;
  }
</style>

![](http://i.cdn.cnn.com/cnn/interactive/2017/politics/trump-tweets/media/trump-tweets-hdr-02.jpg)

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Waarom een tweetanalyse?

Een eerste jaar Donald J. Trump in het witte huis. Misschien wel mede mogelijk gemaakt door zijn karakteristieke uitlatingen op Twitter. In de aanloop van de verkiezingen zijn de tweets van de huidige president van de V.S. een krachtig middel gebleken. Hij bereikt zijn miljoenen kiezers zonder de traditionele media nodig te hebben. Trump zelf verschijnt dan ook relatief weinig voor de camera, in kranten of andere news outlets. 

Om beter vat te krijgen op hoe Trump zijn favoriete medium inzet nemen we zijn tweets onder de loep. **Doormiddel van een tekstanalyse hopen we een aantal vragen te beantwoorden**. 

Simpele vragen zoals:

* Hoeveel tweets stuurt Trump gemiddeld per dag?
* Wanneer op de dag tweet hij met name? s'Avonds, s'ochtends of s'middags?
* Welke tweets worden het meest geretweet en geliked?
* Welke woorden gebruikt Trump het meest?

Maar ook de moeilijke vragen zoals:

* Welke Tweets zijn daadwerkelijk van Trump afkomstig?
* Zijn zijn tweets positief, neutraal of negatief van aard?
* Welke emoties kleuren zijn taalgebruik?
* Wanneer lopen de spanningen hoog op?

Taal is voor een computer moeilijk te vatten. Taal heeft duizenden jaren ontwikkeling meegemaakt en zodoende bereikt het een hoog abstractie niveau. Deze analyse kan dan ook niet 'waterdicht' zijn alleen al om het feit dat iedereen een andere interpretatie heeft van taal. Toch gaan we dit proberen. 

*Deze pagina wordt geupdate als er weer nieuwe inzichten in de analyse naar voren komen*.

# Data verkrijgen

De geïmporteerde dataset is van [Trump Twitter Archive](http://www.trumptwitterarchive.com/archive). Dit is een betere bron dan de Twitter API welke niet altijd alle tweets geeft. Bovendien slaat de Trump Twitter Archive ook verwijderde tweets op. 

De dataset bestaat uit 5.411 tweets vanaf 16-06-2015, de dag dat Donald Trump zich officieel beschiktbaar stelde als kandidaat voor de Republiekeinen.  

De dataset is **gedownload op 04-12-2017**, maar kan terzijnertijd met nieuwe data opnieuw gedownload worden en met één druk op de knop door de 'R script' op deze pagina worden gehaald. De dataset bevat de volgende *zeven* variabelen:

* `text`: tekst van de tweets.
* `created_at`: datum en tijd van tweet in 'GMT'
* `source`: op welk apparaat of met welke software de tweet is gepost
* `retweet_count`: aantal 'retweets'
* `favourite_count`: aantal 'vind-ik-leuks'
* `is_retweet`: of de tweet een retweet is of niet
* `id_str`: uniek karakter van tweet 

## Legenda
Taken die nodig zijn om de hoofdvragen te kunnen beantwoorden zijn weer gegeven als: **1. [x]**. Als je rechts op de grijze code knop drukt komt deze tevoorschijn. De code is ook gedocumenteerd, dat wil zeggen dat alle code met comments uitgelegd word wat het doet.

1. [x] Vind alternatief voor Twitter API want limiet van 3400 tweets en er zit een bug in de twitteR package waardoor incomplete data wordt gegenereerd.
2. [x] Tweet data downloaden vanaf 2015-06-16 (Trump Twitter Archive). De dag dat Trump zich officieel kandidaat stelde voor de republikeinen.

# Data voorbereiden

1. [x] Variabelen in juiste type converteren
2. [x] Filter (subset) data op tweets vanaf Android en iPhone, omdat Trump als persoon hier vandaan tweet
3. [x] Filter data op alleen originele tweets, dus geen Retweets
4. [x] Filter data op de nodige variabelen (kolommen)
5. [x] Filter op daadwerkelijk Trump’s tweets
    * [x] Filter op tweets zonder hashtags, afbeeldingen en links. 
        * Een solide theorie is dat Trump tweet vanaf een Android toestel. Echter sinds Maart 2017 is Trump ook een iPhone gaan gebruiken. Inititief Did Trump Tweet It? heeft machine learning toegepast op de Android tweets. Zo concludeert data scientist David Robinson dat Trump bijna nooit hashtags, afbeeldingen of links gebruikt.
6. [x] Maak nieuwe dataset (store in variable) vanaf inauguratie 2017-01-20

```{r acquire, message=FALSE, warning=FALSE, results='hide'}
# Loading the used libraries
library(tidyverse)
library(lubridate)
library(tidytext)
library(ggthemes)
library(DT)
library(devtools)
library(sentimentr)
library(exploratory) # installed package via: devtools::install_github("exploratory-io/exploratory_func")

# url Trump Twitter Archive
url <- 'http://www.trumptwitterarchive.com/data/realdonaldtrump/%s.json'
# Retrieve all trump's tweets and create dataset with converted `created_at` character dates 
original_df <- map(2009:2017, ~sprintf(url, .x)) %>%
  map_df(jsonlite::fromJSON, simplifyDataFrame = TRUE) %>%
  mutate(created_at = parse_date_time(created_at, "a b! d! H!:M!:S! z!* Y!")) %>%
  tbl_df()
# If above doesn't work download data on website then: 
# original_df <- read.csv("filename.csv", quote = "", comment = "")
```

## Klaarmaken voor analyse: Wanneer zijn de tweets afkomstig van Trump zelf?

Het uiteindelijke doel is om een dataset te maken met unieke Trump tweets. Omdat data scientist David Robinson in zijn analyse, [Text analysis of Trump's tweets confirms he writes only the (angrier) Android half](http://varianceexplained.org/r/trump-tweets/), er vrijwel zeker is dat Trump destijds een Android toestel gebruikte [passen anderen machine learning toe](http://didtrumptweetit.com/).

Robinson concludeert een jaar later in een follow-up: [Trump's Android and iPhone tweets, one year later](http://varianceexplained.org/r/trump-followup/) dat Trump vrijwel altijd tweet:

* zonder links, hashtags of afbeeldingen
* afkomstig van een Android toestel (tot hij een iPhone kocht eind maart 2017) of een iPhone

Wij zullen dat in deze analyse overnemen door de computer op tweets te laten filteren waarvan de `text` hashtags ("#") en/of links ("http") bevatten. Afbeeldingen worden  tegenwoordig niet meer in de text van de tweets meegenomen. Ook nemen we de tweets die vanaf andere toestellen () afkomstig zijn niet mee.

Het spreekt voor zich dat we alleen originele retweets meenemen dus geen retweets. Bovendien zullen gelijk al filteren op de tweets die vanaf zijn inauguratie zijn verstuurd (20-101-2017).

```{r prepare, message=FALSE, warning=FALSE, results='hide'}
# Subset data on high probability that Trump himself is actually tweeting and add
all_tweets <- original_df %>%
  rename(retweets = retweet_count,
         favorites = favorite_count) %>%
  filter(is_retweet != "true",
         source == "Twitter for iPhone" |
         source == "Twitter for Android",
         !grepl("http|#", text)) %>%
  rowid_to_column("ID") %>%
  select(ID, text, created_at, retweets, favorites)
# Get rid of emoji characters R doesn't like them
all_tweets$text <- gsub("[^\x01-\x7F]", "", all_tweets$text)
# The sentimentr package advices to first create sentences (creates lists of sentences per tweet in text column) for faster analysis.
all_tweets$text <- get_sentences(all_tweets$text)
# Add column and let the sentimentr package calculate sentiments per tweet.
all_tweets <- all_tweets %>%
  mutate(sentiment = get_sentiment(text)) %>%
  select(sentiment, text, everything()) # reorder columns
# Round numbers on three decimals
all_tweets$sentiment <- round(all_tweets$sentiment, digits = 3)
# Create dataset since inauguration
president_tweets <- all_tweets %>%
  filter(created_at > "2017-01-20")
# Html widget interactive table in rmarkdown report with only the four useful columns
datatable(head(president_tweets[,c(2,5,6,1,4)], n = nrow(president_tweets)), options = list(pageLength = 5))
```


# Data analyseren

1. [x] Sorteer tweets met meeste Retweets en Favourites
2. [ ] Hoeveel tweets verstuurd Trump gemiddeld per dag
3.  [ ] Tidytext Package tekst analyse
    * [x] unnest_tokens, trek tweets uit elkaar, per woord
    * [x] Verwijder stopwoorden, want onzinnig voor analyse
    * [x] Verwijder cijfers
    * [x] Meest gebruikte woorden
    * [x] Woorden met de meeste retweets en favourites
    * [x] Sentiment analyse per woord
    * [x] Sentiment analyse hele tweet. Visuals per tweet en mediaan sentiment per week.

## Tweets met meeste retweets
Of filter op favorites.

```{r}
# Top 10 retweets
most_rt <- president_tweets %>%
  arrange(desc(retweets))
# Html widget interactive table in rmarkdown report
datatable(head(most_rt[,c(2,5,6,1)], n = nrow(most_rt)), options = list(pageLength = 5)) 
```

## Text analyse per woord
Welke woorden gebruikt Trump het meest in zijn tweets?

### Vanaf Inauguratie

```{r analysis-02, message=FALSE, warning=FALSE}
# Create new dataset `tweets_fy_words` (tweets first year words)
tweets_words <- president_tweets %>%
  unnest(text) %>% # Unnest gets rid of lists in text column
  unnest_tokens(word, text)
# Remove stop words and numbers, which aren't useful
tweets_words <- tweets_words %>%
  anti_join(stop_words) %>%
  filter(!grepl("[0-9]+", word),
         word != "amp") # Because in text is 'space' coded as "amp&"

# Sort on most used words
most_used_words <- tweets_words %>% 
  count(word, sort = TRUE) %>%
  mutate(times_used = n,
         word = reorder(word, times_used)) %>%
  select(word, times_used)
# Convert type word column to charcter for better handeling
most_used_words$word <- as.character(most_used_words$word)
# Sort on times_used
most_used_words <- most_used_words %>%
  arrange(desc(times_used))
# Plot in bar chart
plot_most_used_words <- most_used_words %>%
  top_n(20) %>%
  ggplot(aes(x = reorder(word, times_used), times_used)) +
  geom_col(fill = "#03A9F4") +
  coord_flip() +
  theme_minimal() +
  theme(panel.grid.major.y = element_blank(),
        plot.background = element_blank(),
        plot.title = element_text(size = 18),
        panel.grid.major.x = element_line(colour = "#AFACAC",
                                          linetype = "dotted")) +
  labs(title = "De 20 meest gebruikte woorden in Trump's tweets",
       subtitle = "Vanaf zijn inauguratie op 20-01-2017.",
       x = NULL, 
       y = "Aantal keer gebruikt")
# Plot
plot_most_used_words
# Html widget interactive table in rmarkdown report
datatable(head(most_used_words, n = nrow(most_used_words)), options = list(pageLength = 5)) 
```

### Vanaf kandidaatstelling
Vanaf zijn officiele bekendmaking van kandidaatstelling op 16-06-2015

```{r analysis-03, message=FALSE, warning=FALSE}
# Create new dataset `candidate`
candidate_tweets <- all_tweets %>%
  filter(created_at > "2015-06-16")
# seperte on words
candidate_words <- candidate_tweets %>%
  unnest(text) %>% # Unnest gets rid of lists in text column
  unnest_tokens(word, text)
# Remove stopwords, which are not useful
candidate_words <- candidate_words %>%
  anti_join(stop_words) %>%
  filter(!grepl("[0-9]+", word),
         word != "amp") # Because in text is 'space' coded as "amp&"
# Sort on most used words
most_used_words_candidate <- candidate_words %>% 
  count(word, sort = TRUE) %>%
  mutate(times_used = n,
         word = reorder(word, times_used)) %>%
  select(word, times_used)

# Plot in bar chart
plot_most_used_words_candidate <- most_used_words_candidate %>%
  arrange(desc(times_used)) %>%
  top_n(20) %>%
    ggplot(aes(x = reorder(word, times_used), times_used)) +
    geom_col(fill = "#03A9F4") +
    coord_flip() +
    theme_minimal() +
    theme(panel.grid.major.y = element_blank(),
          plot.background = element_blank(),
          plot.title = element_text(size = 18),
          panel.grid.major.x = element_line(colour = "#AFACAC",
                                            linetype = "dotted")) +
    labs(title = "De 20 meest gebruikte woorden in Trump's tweets",
         subtitle = "Vanaf officiële kandidaatstelling op 16-06-2015.",
         x = NULL, 
         y = "Aantal keer gebruikt")

# Plot
plot_most_used_words_candidate
# Html widget interactive table in rmarkdown report
datatable(head(most_used_words_candidate, n = nrow(most_used_words_candidate)), options = list(pageLength = 5))
```

## Sentimentanalyse

Een sentimentanalyse meet de emotie van een woord. Ik gebruik de [tidytext package](http://tidytextmining.com) (een R library), gemaakt door data scientists *Julia Silge* en *David Robinson*, om verschillende lexicons langs de woorden uit de tweets van Trump te leggen. Via de tidytext package zijn drie 'General-Purpose lexicons' beschikbaar die elk woorden op een andere manier meten.

1. `nrc`: categoriseerd woorden binair (ja/nee) op de sentimenten: *positive, negative, anger, anticipation, disgust, fear, joy, sadness, surprise,* en *trust*.
2. `bing`: categoriseerd woorden binair op *negative* en *positive*.
3. `AFINN` scoort woorden op positief en negatief tussen -5 en 5.

De sentimentanalyse wordt alleen gedaan met de `president_tweets` en `most_used_words` dataset.

### Woorden gescoord op sentiment

Het is allereerst **goed om te weten dat niet alle woorden een 'sentimentele waarde' hebben**. Heel veel woorden zijn neutraal. Zelfstandige naamwoorden bijvoorbeeld of namen van personen die genoemd worden zijn positief noch negatief. Vanaf nu worden alleen de woorden meegenomen die je kan catagoriseren op negatief en positief of 'heel negatief' (-5) tot 'heel positief' (5).

1. [x] Laat verdeling negatieve en positieve woorden zien met `bing` lexicon
2. [x] Hoe ziet de negatieve/positieve verdeling er over het hele jaar uit? `AFINN` lexicon. 
3. [x] Wat is het sentiment (negatief/positief) van de woorden die het meest worden geretweet?
3. [ ] Dubbel check met `sentimentr` package.

```{r lexicon-analysis, message=FALSE, warning=FALSE, fig.width=8.2, fig.height=2.07}
# Colours variable for negative and positive sentiments
colours_pn <- c("#B10026", "#4575B4")

# First use the 'bing' lexicon to see what the distribution is of negative and positive words
most_used_words %>% 
  inner_join(get_sentiments("bing"), by = "word") %>%
  group_by(sentiment) %>%
  summarise(count = n(),
            words = sum(times_used)) %>%
  mutate(total = count * words) %>%
  ggplot(aes(x = sentiment, y = total)) +
  geom_col(aes(fill = sentiment)) +
  geom_text(aes(label = total), 
            hjust = 1.2,
            colour = "white",
            fontface = "bold",
            size = 5) +
  coord_flip() +
  scale_fill_manual(values = colours_pn) +
  theme_minimal() +
  theme(panel.grid.major.y = element_blank(),
        plot.background = element_blank(),
        plot.title = element_text(size = 18),
        panel.grid = element_blank(),
        axis.text.x = element_blank(),
        legend.position = 0) +
  labs(title = "Trump tweet bijna twee keer zoveel negatieve\nals positieve woorden",
       subtitle = "Vanaf inauguratie.",
       x = NULL,
       y = "Aantal woorden")
```

### Sentimentr package
Scoort tweets op sentiment van -1 (heel negatief) tot 1 (heel positief). Een uitleg waarom sentimentr kan je op [hun Github pagina](https://github.com/trinker/sentimentr) lezen. 

Nadat ik alle lexicons geprobeerd heb in combinatie met Trump's tweets heb ik besloten de sentimentr package te gebruiken. De `nrc` vind ik te speculatief want vaak categoriseerd hij één woord dubbel bij verschillende categorieën. De `bing` lexicon scoort binair dus verschil tussen sentiment van tweets kan niet erg goed worden weergegeven. 

```{r sentimentr-viz, message=FALSE, warning=FALSE, fig.width=8.2, fig.height=2.07}
# Add column with catagories positive and negative column
president_tweets <- president_tweets %>% mutate(pos_neg = ifelse(president_tweets$sentiment >= 0, "positive", "negative"))
# Total negative/positve tweets
president_tweets %>%
ggplot(aes(x = pos_neg, fill = pos_neg)) +
  geom_bar(stat = "count") +
  geom_text(stat = "count", aes(label = ..count.., y = ..count..), 
            hjust = 1.2,
            colour = "white",
            fontface = "bold",
            size = 5) +
  coord_flip() +
  scale_fill_manual(values = colours_pn) +
  theme_minimal() +
  theme(panel.grid.major.y = element_blank(),
        plot.background = element_blank(),
        plot.title = element_text(size = 18),
        panel.grid = element_blank(),
        axis.text.x = element_blank(),
        legend.position = 0) +
  labs(title = "Trump verstuurde meer positieve dan negatieve tweets ",
       subtitle = "Vanaf inauguratie.",
       x = NULL,
       y = "Aantal tweets")

```

```{r sentimentr-viz-02, message=FALSE, warning=FALSE,fig.width=8.2, fig.height=4.07}
# Sentiments through time
president_tweets %>%
  ggplot(aes(x = created_at, y = sentiment)) +
  geom_line(aes(colour = pos_neg)) +
  geom_hline(yintercept = 0, color = "black", size = 0.5,
             linetype = "dashed") +
  scale_colour_manual(values = colours_pn) +
  theme_minimal() +
  theme(panel.grid.major.y = element_blank(),
        plot.background = element_blank(),
        plot.title = element_text(size = 18),
        legend.position = 0) +
  labs(title = "Sentiment analyse per tweet",
       subtitle = "Vanaf inauguratie.",
       x = NULL,
       y = "Sentiment")
```

```{r sentimentr-viz-03, message=FALSE, warning=FALSE, fig.width=8.2, fig.height=4.07}
# Sentiments through time with each individual tweet
president_tweets %>%
  ggplot(aes(x = created_at, y = sentiment)) +
  geom_point(aes(colour = pos_neg),
             alpha = 0.7) +
  geom_line(aes(colour = pos_neg),
            size = 0.1) +
  geom_hline(yintercept = 0, color = "black", size = 0.5,
             linetype = "dashed") +
  scale_colour_manual(values = colours_pn) +
  theme_minimal() +
  theme(panel.grid.major.y = element_blank(),
        plot.background = element_blank(),
        plot.title = element_text(size = 18),
        legend.position = 0) +
  labs(title = "Sentiment analyse per tweet",
       subtitle = "Vanaf inauguratie.",
       x = NULL,
       y = "Sentiment")
```


Filter op negatief of positief sentiment of zoek naar bepaalde woorden in tweets.
```{r sent-tweets, message=FALSE, warning=FALSE}
# Dataset sorted by negative sentiment
# HTML widget
datatable(head(president_tweets[,c(2,1)], n = nrow(president_tweets)), options = list(pageLength = 5))
```

### Mediaan sentiment per week

```{r}
# Create dataset with calculated weeks, means, medians, number of tweet per week
president_weeks <- president_tweets %>%
  group_by(week = week(created_at)) %>% 
  mutate(mean = mean(sentiment),
         median = median(sentiment),
         median_pos_neg = ifelse(median >= 0, "positive", "negative"),
         nr_of_tweets = n()) %>%
  ungroup()

# Median sentiment tweets per week
president_weeks %>%
  ggplot(aes(x = week, y = median)) +
  geom_line(size = 0.3) +
  geom_hline(yintercept = 0, 
             color = "black", 
             size = 0.5,
             linetype = "dashed") +  
  geom_point(aes(size = nr_of_tweets,
                 colour = median_pos_neg)) +
  scale_colour_manual(values = colours_pn,
                      guide = FALSE) +
  scale_size_continuous(breaks = seq(0,60,20)) +
  scale_x_continuous(breaks = seq(0,52,5)) +
  theme_minimal() +
  theme(panel.grid.major.y = element_blank(),
        plot.background = element_blank(),
        plot.title = element_text(size = 18),
        legend.position = c(0.9,0.9),
        legend.background = element_rect()) +
  labs(title = "Median sentiment tweets per week",
       subtitle = "Vanaf inauguratie.",
       x = NULL,
       y = "Sentiment")  
```


