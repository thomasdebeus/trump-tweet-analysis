---
title: "Trump's Tweetanalyse"
author: "Thomas de Beus"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    css: style.css
    toc: TRUE
    toc_depth: 5
    theme: journal
    code_folding: hide
    number_sections: true
---
<style>
  #TOC {
    position: fixed;
    left: 0;
    top: 10;
    width: 350px;
    height: 100%;
    overflow:auto;
  }
</style>

![](http://i.cdn.cnn.com/cnn/interactive/2017/politics/trump-tweets/media/trump-tweets-hdr-02.jpg)

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Waarom een tweetanalyse?

Een eerste jaar Donald J. Trump in het witte huis. Misschien wel mede mogelijk gemaakt door zijn karakteristieke uitlatingen op Twitter. In de aanloop van de verkiezingen zijn de tweets van de huidige president van de V.S. een krachtig middel gebleken. Hij bereikt zijn miljoenen kiezers zonder de traditionele media nodig te hebben. Trump zelf verschijnt dan ook relatief weinig voor de camera, in kranten of andere news outlets. 

Om beter vat te krijgen op hoe Trump zijn favoriete medium inzet nemen we zijn tweets onder de loep. **Doormiddel van een tekstanalyse hopen we een aantal vragen te beantwoorden**. 

Simpele vragen zoals:

* Hoeveel tweets stuurt Trump gemiddeld per dag?
* Wanneer op de dag tweet hij met name? s'Avonds, s'ochtends of s'middags?
* Welke tweets worden het meest geretweet en geliked?
* Welke woorden gebruikt Trump het meest?

Maar ook de moeilijke vragen zoals:

* Welke Tweets zijn daadwerkelijk van Trump afkomstig?
* Zijn zijn tweets positief, neutraal of negatief van aard?
* Welke emoties kleuren zijn taalgebruik?
* Wanneer lopen de spanningen hoog op?

Taal is voor een computer moeilijk te vatten. Taal heeft duizenden jaren ontwikkeling meegemaakt en zodoende bereikt het een hoog abstractie niveau. Deze analyse kan dan ook niet 'waterdicht' zijn alleen al om het feit dat iedereen een andere interpretatie heeft van taal. Toch gaan we dit proberen. 

*Deze pagina wordt geupdate als er weer nieuwe inzichten in de analyse naar voren komen*.

# Data verkrijgen

De geïmporteerde dataset is van [Trump Twitter Archive](http://www.trumptwitterarchive.com/archive). Dit is een betere bron dan de Twitter API welke niet altijd alle tweets geeft. Bovendien slaat de Trump Twitter Archive ook verwijderde tweets op. 

De dataset bestaat uit 5.411 tweets vanaf 16-06-2015, de dag dat Donald Trump zich officieel beschiktbaar stelde als kandidaat voor de Republiekeinen.  

De dataset is **gedownload op 04-12-2017**, maar kan terzijnertijd met nieuwe data opnieuw gedownload worden en met één druk op de knop door de 'R script' op deze pagina worden gehaald. De dataset bevat de volgende *zeven* variabelen:

* `text`: tekst van de tweets.
* `created_at`: datum en tijd van tweet in "GMT"
* `source`: op welk apparaat of met welke software de tweet is gepost
* `retweet_count`: aantal 'retweets'
* `favourite_count`: aantal 'vind-ik-leuks'
* `is_retweet`: of de tweet een retweet is of niet
* `id_str`: uniek karakter van tweet 

## Legenda
Taken die nodig zijn om de hoofdvragen te kunnen beantwoorden zijn weer gegeven als: **1. [x]**. Als je rechts op de grijze code knop drukt komt deze tevoorschijn. De code is ook gedocumenteerd, dat wil zeggen dat alle code met comments uitgelegd word wat het doet.

1. [x] Vind alternatief voor Twitter API want limiet van 3400 tweets en er zit een bug in de twitteR package waardoor incomplete data wordt gegenereerd.
2. [x] Tweet data downloaden vanaf 2015-06-16 (Trump Twitter Archive). De dag dat Trump zich officieel kandidaat stelde voor de republikeinen.

# Data voorbereiden

1. [x] Variabelen in juiste type converteren
2. [x] Filter (subset) data op tweets vanaf Android en iPhone, omdat Trump als persoon hier vandaan tweet
3. [x] Filter data op alleen originele tweets, dus geen Retweets
4. [x] Filter data op de nodige variabelen (kolommen)
5. [x] Filter op daadwerkelijk Trump’s tweets
    * [x] Filter op tweets zonder hashtags, afbeeldingen en links. 
        * Een solide theorie is dat Trump tweet vanaf een Android toestel. Echter sinds Maart 2017 is Trump ook een iPhone gaan gebruiken. Inititief Did Trump Tweet It? heeft machine learning toegepast op de Android tweets. Zo concludeert data scientist David Robinson dat Trump bijna nooit hashtags, afbeeldingen of links gebruikt.
6. [x] Maak nieuwe dataset (store in variable) vanaf inauguratie 2017-01-20

```{r acquire, message=FALSE, warning=FALSE, results='hide'}
# Loading the used libraries
library(tidyverse)
library(lubridate)
library(tidytext)
library(DT)
library(sentimentr)
library(exploratory) # installed package via: devtools::install_github("exploratory-io/exploratory_func")
library(scales)
library(hrbrthemes)
library(cowplot)

# url Trump Twitter Archive
url <- 'http://www.trumptwitterarchive.com/data/realdonaldtrump/%s.json'
# Retrieve all trump's tweets and create dataset with converted `created_at` character dates 
original_df <- map(2009:2017, ~sprintf(url, .x)) %>%
  map_df(jsonlite::fromJSON, simplifyDataFrame = TRUE) %>%
  mutate(created_at = parse_date_time(created_at, "a b! d! H!:M!:S! z!* Y!")) %>%
  tbl_df()
# If above doesn't work download data on website then: 
# original_df <- read.csv("filename.csv", quote = "", comment = "")
```

## Klaarmaken voor analyse: Wanneer zijn de tweets afkomstig van Trump zelf?

Het uiteindelijke doel is om een dataset te maken met unieke Trump tweets. Omdat data scientist David Robinson in zijn analyse, [Text analysis of Trump's tweets confirms he writes only the (angrier) Android half](http://varianceexplained.org/r/trump-tweets/), er vrijwel zeker is dat Trump destijds een Android toestel gebruikte [passen anderen machine learning toe](http://didtrumptweetit.com/).

Robinson concludeert een jaar later in een follow-up: [Trump's Android and iPhone tweets, one year later](http://varianceexplained.org/r/trump-followup/) dat Trump vrijwel altijd tweet:

* zonder links, hashtags of afbeeldingen
* afkomstig van een Android toestel (tot hij een iPhone kocht hoogst waarschijnlijk 25-03-2017) of een iPhone.

Wij zullen dat in deze analyse overnemen door de computer op tweets te laten filteren waarvan de `text` hashtags ("#") en/of links ("http") bevatten. Afbeeldingen worden  tegenwoordig niet meer in de text van de tweets meegenomen. Ook nemen we de tweets die vanaf andere toestellen () afkomstig zijn niet mee.

Het spreekt voor zich dat we alleen originele retweets meenemen dus geen retweets. Bovendien zullen gelijk al filteren op de tweets die vanaf zijn inauguratie zijn verstuurd (20-101-2017).

```{r prepare, message=FALSE, warning=FALSE, results='hide'}
# Subset data on high probability that Trump himself is actually tweeting and add
all_trump_tweets <- original_df %>%
  rename(retweets = retweet_count,
         favorites = favorite_count) %>%
  filter(is_retweet != "true",
         source == "Twitter for iPhone" |
         source == "Twitter for Android",
         !grepl("http|#|RT|@realdonaldtrump|@realDonaldTrump", text)) %>%
  rowid_to_column("ID") %>%
  select(ID, text, created_at, retweets, favorites, source)
# Filter out all iPhone tweets before 25-03-2017
all_trump_tweets <- all_trump_tweets %>%
  filter((created_at < "2017-03-25" & source != "Twitter for iPhone") | created_at >= "2017-03-25") %>%
  arrange(desc(created_at))
# Get rid of emoji characters R doesn't like them
all_trump_tweets$text <- gsub("[^\x01-\x7F]", "", all_trump_tweets$text)
# The sentimentr package advices to first create sentences (creates lists of sentences per tweet in text column) for faster analysis.
all_trump_tweets$text <- get_sentences(all_trump_tweets$text)
# Add column and let the sentimentr package calculate sentiments per tweet.
all_trump_tweets <- all_trump_tweets %>%
  mutate(sentiment = get_sentiment(text)) %>%
  select(sentiment, text, everything()) # reorder columns
# Round numbers on three decimals
all_trump_tweets$sentiment <- round(all_trump_tweets$sentiment, digits = 3)
# Convert GMT time to Eastern US time want Trump tweet daarvanuit het meest en originele tijden zijn GMT (Greenwich Time)
all_trump_tweets$created_at <- with_tz(all_trump_tweets$created_at, tzone = "US/Eastern")
# Create dataset since inauguration
president_tweets <- all_trump_tweets %>%
  filter(created_at > "2017-01-20")
# Html widget interactive table in rmarkdown report with only the four useful columns
datatable(head(president_tweets[,c(2,5,6,1,4)], n = nrow(president_tweets)), options = list(pageLength = 5))
```


# Data analyseren

1. [x] Sorteer tweets met meeste Retweets en Favourites
2. [ ] Hoeveel tweets verstuurd Trump gemiddeld per dag
3. [ ] Tidytext Package tekst analyse
    * [x] unnest_tokens, trek tweets uit elkaar, per woord
    * [x] Verwijder stopwoorden, want onzinnig voor analyse
    * [x] Verwijder cijfers
    * [x] Meest gebruikte woorden
    * [x] Woorden met de meeste retweets en favourites
    * [x] Sentiment analyse per woord
    * [x] Sentiment analyse hele tweet. Visuals per tweet en mediaan sentiment per week.

## Tweets met meeste retweets
Of filter op favorites.

```{r}
# Top 10 retweets
most_rt <- president_tweets %>%
  arrange(desc(retweets))
# Html widget interactive table in rmarkdown report
datatable(head(most_rt[,c(2,5,6,1)], n = nrow(most_rt)), options = list(pageLength = 5)) 
```

## Text analyse per woord
Welke woorden gebruikt Trump het meest in zijn tweets?

### Vanaf Inauguratie

```{r analysis-02, message=FALSE, warning=FALSE}
# Create new dataset `tweets_fy_words` (tweets first year words)
tweets_words <- president_tweets %>%
  unnest(text) %>% # Unnest gets rid of lists in text column
  unnest_tokens(word, text)
# Remove stop words and numbers, which aren't useful
tweets_words <- tweets_words %>%
  anti_join(stop_words) %>%
  filter(!grepl("[0-9]+", word),
         word != "amp") # Because in text is 'space' coded as "amp&"

# Sort on most used words
most_used_words <- tweets_words %>% 
  count(word, sort = TRUE) %>%
  mutate(times_used = n,
         word = reorder(word, times_used)) %>%
  select(word, times_used)
# Convert type word column to charcter for better handeling
most_used_words$word <- as.character(most_used_words$word)
# Sort on times_used
most_used_words <- most_used_words %>%
  arrange(desc(times_used))
# Plot in bar chart
plot_most_used_words <- most_used_words %>%
  top_n(20) %>%
  ggplot(aes(x = reorder(word, times_used), times_used)) +
    geom_segment(aes(x = reorder(word, times_used), xend = word, y = 0,yend = times_used),
               colour = "#737373") +
  geom_point(colour = "#03A9F4",
             size = 3) +
  coord_flip() +
  theme_minimal() +
  theme(panel.grid.major.y = element_blank(),
        plot.background = element_blank(),
        plot.title = element_text(face = "bold",
                                  size = 18)) +
  labs(title = "De 20 meest gebruikte woorden in Trump's tweets",
       subtitle = "Vanaf zijn inauguratie op 20-01-2017.",
       x = NULL, 
       y = "Aantal keer gebruikt")

# Plot
plot_most_used_words
# Html widget interactive table in rmarkdown report
datatable(head(most_used_words, n = nrow(most_used_words)), options = list(pageLength = 5)) 
```

Er is ook code om zijn meest gebruikte woorden vanaf zijn kadidaatstelling (16-06-2015) te in te zien, maar wordt niet op deze pagina weergegeven.

```{r analysis-03, message=FALSE, warning=FALSE, results='hide'}
# Create new dataset `candidate`
candidate_tweets <- all_trump_tweets %>%
  filter(created_at > "2015-06-16")
# seperte on words
candidate_words <- candidate_tweets %>%
  unnest(text) %>% # Unnest gets rid of lists in text column
  unnest_tokens(word, text)
# Remove stopwords, which are not useful
candidate_words <- candidate_words %>%
  anti_join(stop_words) %>%
  filter(!grepl("[0-9]+", word),
         word != "amp") # Because in text is 'space' coded as "amp&"
# Sort on most used words
most_used_words_candidate <- candidate_words %>% 
  count(word, sort = TRUE) %>%
  mutate(times_used = n,
         word = reorder(word, times_used)) %>%
  select(word, times_used)

# Plot in bar chart
plot_most_used_words_candidate <- most_used_words_candidate %>%
  arrange(desc(times_used)) %>%
  top_n(20) %>%
    ggplot(aes(x = reorder(word, times_used), times_used)) +
    geom_col(fill = "#03A9F4") +
    coord_flip() +
    theme_minimal() +
    theme(panel.grid.major.y = element_blank(),
          plot.background = element_blank(),
          panel.grid.major.x = element_line(colour = "#AFACAC",
                                            linetype = "dotted"),
          plot.title = element_text(face = "bold",
                                  size = 18)) +
    labs(title = "De 20 meest gebruikte woorden in Trump's tweets",
         subtitle = "Vanaf officiële kandidaatstelling op 16-06-2015.",
         x = NULL, 
         y = "Aantal keer gebruikt")

# Plot
plot_most_used_words_candidate
# Html widget interactive table in rmarkdown report
datatable(head(most_used_words_candidate, n = nrow(most_used_words_candidate)), options = list(pageLength = 5))
```

## Wanneer op de dag tweet Trump doorgaans?

* Trump vanaf toen hij president was
* Trump vanaf dat hij zich officieel kandidaat stelde
* Trump van vóór zijn kandidaatstelling

```{r tweeted-per-weekday, message=FALSE, warning=FALSE, fig.height=5}
# Create dataframe with weekdays
weekday_tweets <- president_tweets %>%
  mutate(hour_of_day = hour(created_at),
         weekday = strftime(created_at, "%a")) %>%
  group_by(weekday, hour_of_day) %>%
  summarize(count = n()) %>%
  mutate(percentage = count / sum(count))
# Order weekdays on Monday first
weekday_tweets$weekday <- factor(weekday_tweets$weekday, levels = c("Mon", 
    "Tue", "Wed", "Thu", "Fri", "Sat", "Sun"))
# Plot distributions
weekday_tweets %>%
  ggplot(aes(hour_of_day, count)) +
  geom_col(fill = "#03A9F4") +
  scale_x_continuous(breaks = seq(0,23,4)) +
  theme_minimal() +
  theme(panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank(),
        plot.title = element_text(face = "bold",
                                  size = 18)) +
  labs(title = "Een week in tweets van president Trump",
       subtitle = "Tweets per uur op de dag sinds zijn inauguratie.",
       x = "Uur van de dag",
       y = "Aantal tweets") +
  facet_wrap(~weekday) 

```


```{r, when-tweeted, message=FALSE, warning=FALSE, fig.height=13.3}
# -------------------President

# Create datframe that groups hours a day and the nr of tweets during his presidency and add percentage column
tweet_time_president <- all_trump_tweets %>%
  mutate(hour_of_day = hour(created_at)) %>%
  filter(created_at > "2017-01-20") %>% # Consists of 1.235 tweets
  group_by(hour_of_day) %>%
  summarize(count = n()) %>%
  mutate(percentage = count / sum(count))
# Plot a bar chart of a day 
plot_tweet_time_president <- tweet_time_president %>%
  ggplot(aes(hour_of_day, percentage)) +
  geom_col(fill = "#03A9F4") +
  theme_minimal() +
  scale_y_continuous(labels = percent_format(),
                     limits=c(0,0.2)) +
  scale_x_continuous(breaks = seq(0,23,2)) +
  theme(panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank(),
        plot.title = element_text(face = "bold",
                                  size = 18)) +
  labs(title = "President Trump",
       subtitle = "Bestaat uit 1.235 tweets.",
       x = "Uur van de dag",
       y = "% van tweets") 

# -------------------Candidate

# Same calculation than `tweet_time_president` but filterd before inauguration and after announcing official canidatcy
tweet_time_candidate <- all_trump_tweets %>%
  mutate(hour_of_day = hour(created_at)) %>%
  filter(created_at < "2017-01-20" &            
           created_at > "2015-06-16") %>% # Consists of 2.493 tweets
  group_by(hour_of_day) %>%
  summarize(count = n()) %>%
  mutate(percentage = count / sum(count))
# Plotting same barchart
plot_tweet_time_candidate <- tweet_time_candidate %>%
  ggplot(aes(hour_of_day, percentage)) +
  geom_col(fill = "#03A9F4") +
  theme_minimal() +
  scale_y_continuous(labels = percent_format(), 
                     limits=c(0,0.2)) +
  scale_x_continuous(breaks = seq(0,23,2)) +
  theme(panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank(),
        plot.title = element_text(face = "bold",
                                  size = 18)) +
  labs(title = "Kandidaat Trump",
       subtitle = "Bestaat uit 2.493 tweets.",
       x = "Uur van de dag",
       y = "% van tweets")  

# --------------------Before Politics

# Same calculation but filterd before announcing official canidatcy
tweet_time_before_politics <- all_trump_tweets %>%
  mutate(hour_of_day = hour(created_at)) %>%
  filter(created_at < "2015-06-16") %>% # Consists of 3.141 tweets
  group_by(hour_of_day) %>%
  summarize(count = n()) %>%
  mutate(percentage = count / sum(count))
# Plotting same barchart
plot_tweet_time_before_politics <- tweet_time_before_politics %>%
  ggplot(aes(hour_of_day, percentage)) +
  geom_col(fill = "#03A9F4") +
  theme_minimal() +
  scale_y_continuous(labels = percent_format(),
                     limits=c(0,0.2)) +
  scale_x_continuous(breaks = seq(0,23,2)) +
  theme(panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank(),
        plot.title = element_text(face = "bold",
                                  size = 18)) +
  labs(title = "Trump vóór officiële politieke carriére ",
       subtitle = "Bestaat uit 3.141 tweets.",
       x = "Uur van de dag",
       y = "% van tweets") 

# Place al three plot's in grid
plot_grid(plot_tweet_time_president, plot_tweet_time_candidate, plot_tweet_time_before_politics, ncol = 1, align = 'v')
```





